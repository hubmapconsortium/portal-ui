{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Remote OME-TIFF Metadata\n",
    "\n",
    "Fetches and displays OME-TIFF metadata from a remote URL using HTTP range requests,\n",
    "without downloading the full file. Useful for troubleshooting image rendering issues\n",
    "in the portal (e.g. verifying dimensions, channels, pyramid levels, physical sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import xml.etree.ElementTree as ET\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Paste the full OME-TIFF URL (including any `?token=` query parameter) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = \"\"\n",
    "\n",
    "if not IMAGE_URL:\n",
    "    raise ValueError(\"IMAGE_URL is required. Paste the full OME-TIFF URL above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: HTTP Range Request Reader\n",
    "\n",
    "All metadata is fetched via `Range` headers so only a few KB are downloaded,\n",
    "even for multi-GB pyramid files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_range(url: str, start: int, end: int) -> bytes:\n",
    "    \"\"\"Fetch a byte range from a remote URL.\"\"\"\n",
    "    r = requests.get(url, headers={\"Range\": f\"bytes={start}-{end}\"}, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "\n",
    "TAG_NAMES = {\n",
    "    254: \"NewSubfileType\",\n",
    "    256: \"ImageWidth\",\n",
    "    257: \"ImageLength\",\n",
    "    258: \"BitsPerSample\",\n",
    "    259: \"Compression\",\n",
    "    262: \"PhotometricInterpretation\",\n",
    "    270: \"ImageDescription\",\n",
    "    273: \"StripOffsets\",\n",
    "    277: \"SamplesPerPixel\",\n",
    "    278: \"RowsPerStrip\",\n",
    "    279: \"StripByteCounts\",\n",
    "    282: \"XResolution\",\n",
    "    283: \"YResolution\",\n",
    "    284: \"PlanarConfiguration\",\n",
    "    296: \"ResolutionUnit\",\n",
    "    305: \"Software\",\n",
    "    317: \"Predictor\",\n",
    "    322: \"TileWidth\",\n",
    "    323: \"TileLength\",\n",
    "    324: \"TileOffsets\",\n",
    "    325: \"TileByteCounts\",\n",
    "    330: \"SubIFDs\",\n",
    "    338: \"ExtraSamples\",\n",
    "    339: \"SampleFormat\",\n",
    "}\n",
    "\n",
    "COMPRESSION_NAMES = {\n",
    "    1: \"None\",\n",
    "    2: \"CCITT RLE\",\n",
    "    5: \"LZW\",\n",
    "    7: \"JPEG\",\n",
    "    8: \"Deflate\",\n",
    "    32946: \"Deflate\",\n",
    "    34712: \"JPEG 2000\",\n",
    "}\n",
    "\n",
    "\n",
    "def _unpack_ifd_value(byte_order: str, dtype: int, val_bytes: bytes):\n",
    "    \"\"\"Unpack the value/offset field of a TIFF IFD entry.\"\"\"\n",
    "    if dtype == 3:  # SHORT\n",
    "        return struct.unpack(f\"{byte_order}H\", val_bytes[:2])[0]\n",
    "    if dtype == 4:  # LONG\n",
    "        return struct.unpack(f\"{byte_order}I\", val_bytes[:4])[0]\n",
    "    if dtype == 16:  # LONG8 (BigTIFF)\n",
    "        return struct.unpack(f\"{byte_order}Q\", val_bytes[:8])[0]\n",
    "    return struct.unpack(f\"{byte_order}Q\", val_bytes[:8])[0]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IFDEntry:\n",
    "    tag: int\n",
    "    dtype: int\n",
    "    count: int\n",
    "    value: int\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return TAG_NAMES.get(self.tag, f\"Tag_{self.tag}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IFDSummary:\n",
    "    \"\"\"Summary of a single TIFF IFD (image or sub-image).\"\"\"\n",
    "    width: int = 0\n",
    "    height: int = 0\n",
    "    bits_per_sample: int = 0\n",
    "    samples_per_pixel: int = 1\n",
    "    compression: int = 1\n",
    "    tile_width: int = 0\n",
    "    tile_height: int = 0\n",
    "    subifd_offsets: list = field(default_factory=list)\n",
    "    entries: list = field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def compression_name(self):\n",
    "        return COMPRESSION_NAMES.get(self.compression, str(self.compression))\n",
    "\n",
    "    def short_desc(self, label: str = \"\") -> str:\n",
    "        tile = f\", tiles={self.tile_width}x{self.tile_height}\" if self.tile_width else \"\"\n",
    "        prefix = f\"{label}: \" if label else \"\"\n",
    "        return (\n",
    "            f\"{prefix}{self.width}x{self.height}, \"\n",
    "            f\"{self.bits_per_sample}-bit x{self.samples_per_pixel}ch, \"\n",
    "            f\"compression={self.compression_name}{tile}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: TIFF / BigTIFF IFD Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ifd(url: str, offset: int, byte_order: str, *, bigtiff: bool) -> tuple[IFDSummary, int]:\n",
    "    \"\"\"Read a single IFD from a remote TIFF.\n",
    "\n",
    "    Returns (IFDSummary, next_ifd_offset).  next_ifd_offset is 0 when\n",
    "    there are no more IFDs in the chain.\n",
    "    \"\"\"\n",
    "    if bigtiff:\n",
    "        count_size, entry_size, ptr_size, count_fmt, ptr_fmt = 8, 20, 8, \"Q\", \"Q\"\n",
    "    else:\n",
    "        count_size, entry_size, ptr_size, count_fmt, ptr_fmt = 2, 12, 4, \"H\", \"I\"\n",
    "\n",
    "    count_data = fetch_range(url, offset, offset + count_size - 1)\n",
    "    num_entries = struct.unpack(f\"{byte_order}{count_fmt}\", count_data)[0]\n",
    "\n",
    "    entries_start = offset + count_size\n",
    "    entries_data = fetch_range(url, entries_start, entries_start + num_entries * entry_size - 1)\n",
    "\n",
    "    summary = IFDSummary()\n",
    "    for i in range(num_entries):\n",
    "        raw = entries_data[i * entry_size:(i + 1) * entry_size]\n",
    "        if bigtiff:\n",
    "            tag, dtype, count = struct.unpack(f\"{byte_order}HHQ\", raw[:12])\n",
    "            val_bytes = raw[12:20]\n",
    "        else:\n",
    "            tag, dtype, count = struct.unpack(f\"{byte_order}HHI\", raw[:8])\n",
    "            val_bytes = raw[8:12]\n",
    "\n",
    "        val = _unpack_ifd_value(byte_order, dtype, val_bytes)\n",
    "        entry = IFDEntry(tag=tag, dtype=dtype, count=count, value=val)\n",
    "        summary.entries.append(entry)\n",
    "\n",
    "        if tag == 256:\n",
    "            summary.width = val\n",
    "        elif tag == 257:\n",
    "            summary.height = val\n",
    "        elif tag == 258:\n",
    "            summary.bits_per_sample = val\n",
    "        elif tag == 259:\n",
    "            summary.compression = val\n",
    "        elif tag == 277:\n",
    "            summary.samples_per_pixel = val\n",
    "        elif tag == 322:\n",
    "            summary.tile_width = val\n",
    "        elif tag == 323:\n",
    "            summary.tile_height = val\n",
    "        elif tag == 330:  # SubIFDs\n",
    "            if bigtiff:\n",
    "                sub_data = fetch_range(url, val, val + count * 8 - 1)\n",
    "                summary.subifd_offsets = list(struct.unpack(f\"{byte_order}{count}Q\", sub_data))\n",
    "            else:\n",
    "                sub_data = fetch_range(url, val, val + count * 4 - 1)\n",
    "                summary.subifd_offsets = list(struct.unpack(f\"{byte_order}{count}I\", sub_data))\n",
    "\n",
    "    # Next IFD pointer follows the entries\n",
    "    next_ptr_offset = entries_start + num_entries * entry_size\n",
    "    next_data = fetch_range(url, next_ptr_offset, next_ptr_offset + ptr_size - 1)\n",
    "    next_ifd = struct.unpack(f\"{byte_order}{ptr_fmt}\", next_data)[0]\n",
    "\n",
    "    return summary, next_ifd\n",
    "\n",
    "\n",
    "def fetch_string_tag(url: str, entry: IFDEntry, byte_order: str, *, max_bytes: int = 65536) -> str:\n",
    "    \"\"\"Fetch the string value of a TIFF tag (e.g. ImageDescription, Software).\"\"\"\n",
    "    nbytes = min(entry.count, max_bytes)\n",
    "    data = fetch_range(url, entry.value, entry.value + nbytes - 1)\n",
    "    return data.decode(\"utf-8\", errors=\"replace\").rstrip(\"\\x00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read TIFF Header and First IFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 34,385,907,269 bytes (32.02 GB)\n",
      "Accept-Ranges: bytes\n",
      "Format: BigTIFF (big-endian)\n",
      "First IFD offset: 34,361,978,704\n",
      "\n",
      "First IFD: 49152x65536, 16-bit x1ch, compression=None, tiles=512x512\n",
      "  18 tags, 8 sub-IFDs\n",
      "  Software: OME Bio-Formats 7.1.0\n"
     ]
    }
   ],
   "source": [
    "# Verify the server supports range requests and get file size\n",
    "head = requests.head(IMAGE_URL, timeout=15)\n",
    "head.raise_for_status()\n",
    "file_size = int(head.headers.get(\"Content-Length\", 0))\n",
    "accepts_ranges = head.headers.get(\"Accept-Ranges\", \"none\")\n",
    "print(f\"File size: {file_size:,} bytes ({file_size / (1024**3):.2f} GB)\")\n",
    "print(f\"Accept-Ranges: {accepts_ranges}\")\n",
    "if accepts_ranges == \"none\":\n",
    "    raise RuntimeError(\"Server does not support range requests — cannot read metadata without downloading the full file.\")\n",
    "\n",
    "# Read the 8-byte TIFF header\n",
    "header = fetch_range(IMAGE_URL, 0, 15)  # fetch 16 bytes to cover BigTIFF header\n",
    "\n",
    "byte_order = \"<\" if header[:2] == b\"II\" else \">\"\n",
    "magic = struct.unpack(f\"{byte_order}H\", header[2:4])[0]\n",
    "bigtiff = magic == 43\n",
    "\n",
    "if bigtiff:\n",
    "    offset_size = struct.unpack(f\"{byte_order}H\", header[4:6])[0]\n",
    "    first_ifd_offset = struct.unpack(f\"{byte_order}Q\", header[8:16])[0]\n",
    "    print(f\"Format: BigTIFF ({'little' if byte_order == '<' else 'big'}-endian)\")\n",
    "else:\n",
    "    first_ifd_offset = struct.unpack(f\"{byte_order}I\", header[4:8])[0]\n",
    "    print(f\"Format: Classic TIFF ({'little' if byte_order == '<' else 'big'}-endian)\")\n",
    "\n",
    "print(f\"First IFD offset: {first_ifd_offset:,}\")\n",
    "\n",
    "# Read first IFD\n",
    "first_ifd, next_ifd_offset = read_ifd(IMAGE_URL, first_ifd_offset, byte_order, bigtiff=bigtiff)\n",
    "print(f\"\\nFirst IFD: {first_ifd.short_desc()}\")\n",
    "print(f\"  {len(first_ifd.entries)} tags, {len(first_ifd.subifd_offsets)} sub-IFDs\")\n",
    "\n",
    "# Fetch Software tag if present\n",
    "for entry in first_ifd.entries:\n",
    "    if entry.tag == 305:\n",
    "        software = fetch_string_tag(IMAGE_URL, entry, byte_order)\n",
    "        print(f\"  Software: {software}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parse OME-XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OME-XML size: 23,140,345 bytes\n",
      "\n",
      "OME attributes:\n",
      "  Creator: Nanostring GeoMx 3.1.0.222\n",
      "  UUID: urn:uuid:d03b1055-c4a7-498e-950e-0b10733fa0d4\n"
     ]
    }
   ],
   "source": [
    "# Find ImageDescription tag (270) — contains the OME-XML\n",
    "desc_entry = next((e for e in first_ifd.entries if e.tag == 270), None)\n",
    "\n",
    "if desc_entry is None:\n",
    "    raise RuntimeError(\"No ImageDescription tag found — this may not be an OME-TIFF.\")\n",
    "\n",
    "print(f\"OME-XML size: {desc_entry.count:,} bytes\")\n",
    "\n",
    "# Fetch the full OME-XML (can be multiple MB for files with many ROIs)\n",
    "ome_xml = fetch_range(IMAGE_URL, desc_entry.value, desc_entry.value + desc_entry.count - 1)\n",
    "ome_xml = ome_xml.decode(\"utf-8\", errors=\"replace\").rstrip(\"\\x00\")\n",
    "\n",
    "root = ET.fromstring(ome_xml)\n",
    "ns = \"\"\n",
    "if \"}\" in root.tag:\n",
    "    ns = root.tag.split(\"}\")[0] + \"}\"\n",
    "\n",
    "# Print top-level OME attributes\n",
    "print(f\"\\nOME attributes:\")\n",
    "for k, v in root.attrib.items():\n",
    "    if \"schemaLocation\" not in k:\n",
    "        print(f\"  {k.split('}')[-1]}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Image & Pixel Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 3041_pB_M (Image:0)\n",
      "  Acquired: 2022-09-16T19:29:35.739\n",
      "  Dimensions: 49152 x 65536 px\n",
      "  SizeZ=1, SizeC=4, SizeT=1\n",
      "  Pixel type: uint16 (16-bit significant)\n",
      "  Dimension order: XYZCT\n",
      "  Interleaved: false\n",
      "  Physical pixel size: 0.400673121 µm x 0.399840057 µm\n",
      "  Total physical size: 19693.89 x 26203.92 µm\n",
      "  Channels (4):\n",
      "    Channel:0:0: FITC/525nm  fluor=SYTO 13  color=65279  spp=1\n",
      "    Channel:0:1: Cy3/568nm  fluor=Alexa 532  color=16646399  spp=1\n",
      "    Channel:0:2: Texas Red/615nm  fluor=Alexa 594  color=-16908033  spp=1\n",
      "    Channel:0:3: Cy5/666nm  fluor=Cy5  color=-33554177  spp=1\n",
      "  Planes (4):\n",
      "    C=0 Z=0 T=0  exposure=100.0 µs\n",
      "    C=1 Z=0 T=0  exposure=300.0 µs\n",
      "    C=2 Z=0 T=0  exposure=300.0 µs\n",
      "    C=3 Z=0 T=0  exposure=300.0 µs\n"
     ]
    }
   ],
   "source": [
    "for img in root.findall(f\"{ns}Image\"):\n",
    "    img_id = img.get(\"ID\", \"\")\n",
    "    img_name = img.get(\"Name\", \"\")\n",
    "    acq_date = \"\"\n",
    "    acq_el = img.find(f\"{ns}AcquisitionDate\")\n",
    "    if acq_el is not None and acq_el.text:\n",
    "        acq_date = acq_el.text\n",
    "\n",
    "    print(f\"Image: {img_name} ({img_id})\")\n",
    "    if acq_date:\n",
    "        print(f\"  Acquired: {acq_date}\")\n",
    "\n",
    "    pixels = img.find(f\"{ns}Pixels\")\n",
    "    if pixels is None:\n",
    "        print(\"  (no Pixels element)\")\n",
    "        continue\n",
    "\n",
    "    attrs = pixels.attrib\n",
    "    print(f\"  Dimensions: {attrs.get('SizeX')} x {attrs.get('SizeY')} px\")\n",
    "    print(f\"  SizeZ={attrs.get('SizeZ', '1')}, SizeC={attrs.get('SizeC', '1')}, SizeT={attrs.get('SizeT', '1')}\")\n",
    "    print(f\"  Pixel type: {attrs.get('Type')} ({attrs.get('SignificantBits', '?')}-bit significant)\")\n",
    "    print(f\"  Dimension order: {attrs.get('DimensionOrder')}\")\n",
    "    print(f\"  Interleaved: {attrs.get('Interleaved', 'false')}\")\n",
    "\n",
    "    phys_x = attrs.get(\"PhysicalSizeX\")\n",
    "    phys_y = attrs.get(\"PhysicalSizeY\")\n",
    "    unit_x = attrs.get(\"PhysicalSizeXUnit\", \"\\u00b5m\")\n",
    "    unit_y = attrs.get(\"PhysicalSizeYUnit\", \"\\u00b5m\")\n",
    "    if phys_x and phys_y:\n",
    "        print(f\"  Physical pixel size: {phys_x} {unit_x} x {phys_y} {unit_y}\")\n",
    "        total_x = int(attrs[\"SizeX\"]) * float(phys_x)\n",
    "        total_y = int(attrs[\"SizeY\"]) * float(phys_y)\n",
    "        print(f\"  Total physical size: {total_x:.2f} x {total_y:.2f} {unit_x}\")\n",
    "\n",
    "    # Channels\n",
    "    channels = pixels.findall(f\"{ns}Channel\")\n",
    "    if channels:\n",
    "        print(f\"  Channels ({len(channels)}):\")\n",
    "        for ch in channels:\n",
    "            ch_name = ch.get(\"Name\", \"\")\n",
    "            ch_fluor = ch.get(\"Fluor\", \"\")\n",
    "            ch_color = ch.get(\"Color\", \"\")\n",
    "            ch_spp = ch.get(\"SamplesPerPixel\", \"1\")\n",
    "            print(f\"    {ch.get('ID')}: {ch_name}  fluor={ch_fluor}  color={ch_color}  spp={ch_spp}\")\n",
    "\n",
    "    # Planes (exposure times, z/c/t indices)\n",
    "    planes = pixels.findall(f\"{ns}Plane\")\n",
    "    if planes:\n",
    "        print(f\"  Planes ({len(planes)}):\")\n",
    "        for pl in planes:\n",
    "            exp = pl.get(\"ExposureTime\", \"\")\n",
    "            exp_unit = pl.get(\"ExposureTimeUnit\", \"\")\n",
    "            print(\n",
    "                f\"    C={pl.get('TheC')} Z={pl.get('TheZ')} T={pl.get('TheT')}\"\n",
    "                + (f\"  exposure={exp} {exp_unit}\" if exp else \"\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Pyramid Levels (Sub-IFDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Full resolution (IFD 0): {first_ifd.short_desc()}\")\n",
    "\n",
    "if first_ifd.subifd_offsets:\n",
    "    print(f\"\\nPyramid sub-IFDs ({len(first_ifd.subifd_offsets)} levels):\")\n",
    "    for i, off in enumerate(first_ifd.subifd_offsets):\n",
    "        sub, _ = read_ifd(IMAGE_URL, off, byte_order, bigtiff=bigtiff)\n",
    "        print(f\"  Level {i + 1}: {sub.short_desc()}\")\n",
    "else:\n",
    "    print(\"\\nNo sub-IFDs (no pyramid / single resolution).\")\n",
    "\n",
    "# Walk the top-level IFD chain to find additional channels\n",
    "channel_ifds = []\n",
    "ifd_offset = next_ifd_offset\n",
    "while ifd_offset != 0 and len(channel_ifds) < 20:\n",
    "    ifd_summary, ifd_offset = read_ifd(IMAGE_URL, ifd_offset, byte_order, bigtiff=bigtiff)\n",
    "    channel_ifds.append(ifd_summary)\n",
    "\n",
    "if channel_ifds:\n",
    "    print(f\"\\nAdditional top-level IFDs ({len(channel_ifds)}):\")\n",
    "    for i, ifd in enumerate(channel_ifds):\n",
    "        print(f\"  IFD {i + 1}: {ifd.short_desc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Structured Annotations\n",
    "\n",
    "OME-XML can contain vendor-specific metadata (e.g. channel intensity ranges,\n",
    "biological targets, instrument info) in `<StructuredAnnotations>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = root.find(f\"{ns}StructuredAnnotations\")\n",
    "if sa is None:\n",
    "    print(\"No StructuredAnnotations found.\")\n",
    "else:\n",
    "    annotations = list(sa)\n",
    "    print(f\"{len(annotations)} annotation(s):\\n\")\n",
    "    for ann in annotations:\n",
    "        ann_id = ann.get(\"ID\", \"\")\n",
    "        ann_type = ann.tag.replace(ns, \"\")\n",
    "        value_el = ann.find(f\"{ns}Value\")\n",
    "        if value_el is not None and len(value_el) > 0:\n",
    "            # XML annotation — print the inner element name and text content\n",
    "            inner = value_el[0]\n",
    "            inner_tag = inner.tag.replace(ns, \"\")\n",
    "            # Collect leaf text values\n",
    "            fields = {child.tag.replace(ns, \"\"): (child.text or \"\").strip() for child in inner}\n",
    "            print(f\"  {ann_id} ({ann_type}/{inner_tag}): {fields}\")\n",
    "        elif value_el is not None and value_el.text:\n",
    "            text = value_el.text.strip()\n",
    "            print(f\"  {ann_id} ({ann_type}): {text[:200]}{'...' if len(text) > 200 else ''}\")\n",
    "        else:\n",
    "            print(f\"  {ann_id} ({ann_type}): (empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: ROIs\n",
    "\n",
    "ROIs defined in the OME-XML (e.g. scan regions for spatial transcriptomics instruments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = root.findall(f\"{ns}ROI\")\n",
    "roi_refs = root.findall(f\".//{ns}ROIRef\")\n",
    "\n",
    "if not rois:\n",
    "    print(\"No ROIs defined.\")\n",
    "else:\n",
    "    print(f\"{len(rois)} ROI(s) defined, {len(roi_refs)} ROIRef(s) in images:\\n\")\n",
    "    for roi in rois[:25]:  # cap at 25 to avoid excessive output\n",
    "        roi_id = roi.get(\"ID\", \"\")\n",
    "        roi_name = roi.get(\"Name\", \"\")\n",
    "        union = roi.find(f\"{ns}Union\")\n",
    "        shapes = list(union) if union is not None else []\n",
    "        shape_types = [s.tag.replace(ns, \"\") for s in shapes]\n",
    "        print(f\"  {roi_id}: {roi_name or '(unnamed)'}  shapes={shape_types}\")\n",
    "        for shape in shapes:\n",
    "            shape_type = shape.tag.replace(ns, \"\")\n",
    "            relevant_attrs = {k: v for k, v in shape.attrib.items() if k not in (\"ID\",)}\n",
    "            if relevant_attrs:\n",
    "                print(f\"    {shape_type}: {relevant_attrs}\")\n",
    "    if len(rois) > 25:\n",
    "        print(f\"  ... and {len(rois) - 25} more ROI(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw OME-XML (first 5000 characters)\n",
    "\n",
    "For reference / quick inspection of the raw XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ome_xml[:5000])\n",
    "if len(ome_xml) > 5000:\n",
    "    print(f\"\\n... truncated ({len(ome_xml):,} total characters)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "figure-generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
